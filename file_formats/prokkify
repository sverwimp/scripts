#!/usr/bin/env python3

import argparse
import bz2
import gzip
import re
import sys
from typing import List, Tuple


def is_gzipped(path: str) -> bool:
    with open(path, "rb") as f:
        return f.read(2) == b"\x1f\x8b"
    

def is_bzipped(path: str) -> bool:
    with open(path, "rb") as f:
        return f.read(3) == b"BZh"


def open_file(path: str, mode: str = "rt"):
    if is_gzipped(path):
        return gzip.open(path, mode)
    elif is_bzipped(path):
        return bz2.open(path, mode)
    return open(path, mode)


def clean_id(identifier: str) -> str:
    """Strips NCBI prefixes like lcl| or gnl| for matching."""
    if "|" in identifier:
        return identifier.split("|")[-1]
    return identifier


def parse_location(loc: str) -> List[Tuple[str, str, str]]:
    """Parses GenBank locations into GFF coordinates and strand."""
    strand = "-" if "complement" in loc else "+"
    core = loc.replace("complement(", "").replace("join(", "")
    while core.endswith(")"): core = core[:-1]
    
    parts = []
    for segment in core.split(","):
        nums = re.findall(r"\d+", segment)
        if len(nums) >= 2:
            parts.append((nums[0], nums[-1], strand))
        elif len(nums) == 1:
            parts.append((nums[0], nums[0], strand))
    return parts


def format_gff_attrs(feat_type: str, attrs: dict, remove_translation: bool = False) -> str:
    """Format and clean attributes for GFF3 compatibility."""
    gff_attrs = {}
    
    fid = attrs.get("locus_tag") or attrs.get("protein_id") or attrs.get("gene")
    if fid:
        # We use the type-ID format for uniqueness
        gff_attrs["ID"] = f"{feat_type.lower()}-{fid}"
        if "locus_tag" in attrs:
            gff_attrs["locus_tag"] = attrs["locus_tag"]

    fname = attrs.get("gene", fid)
    if fname:
        gff_attrs["Name"] = fname

    # Consolidation of GO terms
    go_terms = []
    for k, v in attrs.items():
        if k.lower().startswith("go_"):
            found = re.findall(r"GO:\d+", v)
            go_terms.extend(found)
    if go_terms:
        gff_attrs["Ontology_term"] = ",".join(sorted(set(go_terms)))

    for k in ["gene", "product", "protein_id", "note", "inference"]:
        if k in attrs and k not in gff_attrs:
            gff_attrs[k] = attrs[k]
    
    if remove_translation:
        gff_attrs.pop("translation", None)
    elif "translation" in attrs:
        gff_attrs["translation"] = "".join(attrs["translation"].split())

    items = []
    for k, v in gff_attrs.items():
        # Don't escape commas in Ontology_term (they're used as separators)
        if k == "Ontology_term":
            safe_v = str(v).replace(";", "%3B").replace("=", "%3D").replace("&", "%26")
        else:
            safe_v = str(v).replace(";", "%3B").replace("=", "%3D").replace("&", "%26").replace(",", "%2C")
        items.append(f"{k}={safe_v}")

    return ";".join(items)


def extract_method_from_note(note: str) -> str:
    """Extract prediction method from PGAP-style notes."""
    if not note:
        return None
    # Look for "gene prediction method: XXXX."
    match = re.search(r'gene prediction method:\s*([^.]+)', note)
    if match:
        return match.group(1).strip()
    return None


def parse_genbank(path: str):
    """Generator yielding contig records from a GenBank file.

    Result dictionary structure:
    {
    "seqid": str, - Contig identifier
    "features": [
        {"type": str, - Feature type (e.g., CDS, gene, source)
        "loc": str, - Location string (e.g., complement("1..201"))
        "attrs": {...} - Attributes dictionary
        },
    "sequence": str - Full nucleotide sequence of the contig
    }

    where features have attributes depending on their type
    Attributes dictionary may contain:
        gene: str - Gene name
        locus_tag: str - Locus tag
        EC_number: str - Enzyme Commission number
        inference: str - Inference information
        note: str - Notes
        GO_function: str - GO function terms
        GO_process: str - GO process terms
        codon_start: str - Codon start
        transl_table: str - Translation table
        product: str - Product description
        protein_id: str - Protein identifier
        translation: str - Amino acid sequence
        ... and many more (https://labinfoman.com/app/bxseqtools/help_gb_format.php)
    (for type == "source"):
        organism: str - Organism name
        mol_type: str - Molecule type
        db_xref: str - Database cross-references (TaxID, etc.)
    """
    with open_file(path, "rt") as fh:
        record = {"seqid": None, "features": [], "sequence": []}
        current_feat = None
        current_qual = None
        state = "HEADER"

        for line in fh:
            line = line.rstrip()
            if not line: continue
            if line.startswith("LOCUS"):
                record["seqid"] = line.split()[1]
            elif line.startswith("FEATURES"):
                state = "FEATURES"
            elif line.startswith("ORIGIN"):
                state = "ORIGIN"
            elif line.startswith("//"):
                record["sequence"] = "".join(record["sequence"])
                yield record
                record = {"seqid": None, "features": [], "sequence": []}
                state = "HEADER"
            elif state == "FEATURES":
                if line.startswith(" " * 5) and not line.startswith(" " * 21):
                    parts = line.split()
                    if len(parts) >= 2:
                        current_feat = {"type": parts[0], "loc": parts[1], "attrs": {}}
                        record["features"].append(current_feat)
                        current_qual = None
                elif line.startswith(" " * 21) and current_feat is not None:
                    content = line.strip()
                    if content.startswith("/"):
                        if "=" in content:
                            key, val = content[1:].split("=", 1)
                            val = val.strip('"')
                            current_feat["attrs"][key] = val
                            current_qual = key
                        else:
                            current_feat["attrs"][content[1:]] = "true"
                            current_qual = content[1:]
                    elif current_qual:
                        current_feat["attrs"][current_qual] += " " + content.strip('"')
            elif state == "ORIGIN":
                record["sequence"].append(re.sub(r"[^acgtACGTnN]", "", line).upper())


def genbank_to_gff(genbank_path: str, out, remove_translation: bool = False):
    """Convert GenBank to Prokka-like GFF format."""
    records = list(parse_genbank(genbank_path)) # materialize for second pass (FASTA)

    out.write("##gff-version 3\n")
    out.write("#!Converted from GenBank to Prokka-like GFF by prokkify\n")
    for rec in records:
        out.write(f"##sequence-region {rec['seqid']} 1 {len(rec['sequence'])}\n")

        # species directive from source feature taxon
        source_feat = next((f for f in rec.get("features", []) if f["type"] == "source"), None)
        if source_feat:
            taxon_id = re.search(r"taxon:(\d+)", source_feat.get("attrs", {}).get("db_xref", ""))
            taxon_url = f"https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id={taxon_id.group(1)}" if taxon_id else ""
            if taxon_url:
                out.write(f"##species {taxon_url}\n")
        
        out.write(f"{rec['seqid']}\tLocal\tregion\t1\t{len(rec['sequence'])}\t.\t+\t.\tID={rec['seqid']}:1..{len(rec['sequence'])};Name={rec['seqid']}\n")
        
        for feat in rec["features"]:
            if feat["type"] == "source": continue
            # Determine source field based on feature type and note
            if feat["type"] == "gene":
                source = "."
            else:
                method = extract_method_from_note(feat["attrs"].get("note"))
                source = method if method else "." #if method else "GenBank"
            
            locs = parse_location(feat["loc"])
            attr_str = format_gff_attrs(feat["type"], feat["attrs"], remove_translation=remove_translation)
            for start, end, strand in locs:
                out.write(f"{rec['seqid']}\t{source}\t{feat['type']}\t{start}\t{end}\t.\t{strand}\t0\t{attr_str}\n")

    out.write("##FASTA\n")
    for rec in records:
        out.write(f">{rec['seqid']}\n")
        for i in range(0, len(rec['sequence']), 60):
            out.write(rec['sequence'][i:i+60] + "\n")


def gff_fasta_to_gff(gff_path: str, fasta_path: str, out):
    """Convert GFF + FASTA to Prokka-like GFF format.
    Extracts sequences from the FASTA and appends them to a copy of the existing GFF.
    """
    sequences = {}
    with open_file(fasta_path, "rt") as fh:
        current = None
        for line in fh:
            if line.startswith(">"):
                full_id = line[1:].strip().split()[0]
                current = clean_id(full_id)
                sequences[current] = []
            elif current:
                sequences[current].append(line.strip().upper())

    with open_file(gff_path, "rt") as fh:
        first_line = fh.readline() # Should be gff-version line
        out.write(first_line)
        out.write("#!Converted from GFF+FASTA to Prokka-like GFF by prokkify\n")
        for line in fh:
            out.write(line)
    
    out.write("##FASTA\n")
    for cid in sequences:
        out.write(f">{cid}\n")
        full_seq = "".join(sequences[cid])
        for i in range(0, len(full_seq), 60):
            out.write(full_seq[i:i+60] + "\n")
   

def main():
    parser = argparse.ArgumentParser(
        description=(
            "Convert GenBank or GFF+FASTA to Prokka-like GFF3.\n\n"
            "Input must be either:\n"
            "  --genbank <file>\n"
            "or:\n"
            "  --gff <file> --fasta <file>\n\n"
            "Input files may be gzipped (.gz) or bzipped (.bz2). Output is written to stdout "
            "unless --out is specified."
        ),
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("--genbank", help="Input GenBank file")
    parser.add_argument("--gff", help="Input GFF file")
    parser.add_argument("--fasta", help="Input FASTA file")
    parser.add_argument("--remove-translation", action="store_true",
                        help="Remove 'translation' attribute from output GFF build using --genbank input")
    parser.add_argument("--out", help="Output GFF file (default: stdout)")

    args = parser.parse_args() 

    out = open(args.out, "w") if args.out else sys.stdout
    if args.genbank and (args.gff or args.fasta):
        print("Warning: only one of --genbank or --gff/--fasta should be provided.")
        print("Proceeding with --genbank input.")
    
    try:
        if args.genbank:
            genbank_to_gff(args.genbank, out, remove_translation=args.remove_translation)
        elif args.gff and args.fasta:
            gff_fasta_to_gff(args.gff, args.fasta, out)
        else:
            parser.print_help()
            sys.exit(1)
    except BrokenPipeError:
        devnull = open('/dev/null', 'w')
        sys.stdout = devnull
    finally:
        if args.out: out.close()
        sys.exit(0)


if __name__ == "__main__":
    main()
